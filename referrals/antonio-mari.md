To whom it may concern,

I am pleased to write in my highest possible support of Antonio Mari’s application to XXX. I am a postdoctoral researcher at Northeastern University in David Bau’s interpretable deep learning lab. In our lab, we ask how deep neural networks achieve their remarkable capabilities and whether we can make their internal computations legible to humans. Our field recently got popularized under the umbrella term of mechanistic interpretability. I have been extremely fortunate to advise Antonio during his semester project in my former lab at EPFL, while starting my new role in the United States. Among the 33 undergraduate students I have advised so far Antonio ranks among the top 3 students as a real allrounder, with a deep interset into theory, outstanding technical capabilities, great communication skills. In terms of leadership Antonio ranks at number 1 among this reference group.

Antonio joined me and Viacheslav Surkov, another brilliant undergraduate student at EPFL, in our efforts to advance the field of mechanistic interpretability of text-to-image models like SDXL and FLUX. In contrast to mechanistic interpretability for large language models (LLMs), the field for text-to-image models is more immature. Viacheslav and I made some good progress on reverse engineering parts of U-net based models like SDXL using sparse autoencoders (SAEs). SAEs are a recent mechanistic interpretability technique that allows to decompose intermediate results of a neural network forward pass into sparse sums of interpretable features. In SDXL they revealed specialization among the different layers of the network and many of our learned features almost act like semantic brush tools interpretably changing the generated images when we turn up or down the features values within a spatial region. However, because our insights and methods were limited to the single model family of SDXL and its distillations and finetunes, we were unable to convince the broader scientific community about the value of our work.

This is where Antonio's project comes in. His role was to advance our understanding of more recent, state-of-the-art, diffusion transformer based text-to-image models like FLUX. To be crystal clear here, the straightforward adaptation our work on U-net based models did not work for the diffusion transformer based ones including FLUX up until this point. In order to get a handle on FLUX, we let Antonio open-endedly explore it without necessarily pushing towards completing our prior work by extending it to this diffusion transformer based model. Only the best students that I have worked with are able to excell in an open-ended problem formulation like this. I already knew Antonio and that he has extraordinary capabilities from advising him for a class project in his reinforcement learning class, where he led a team of three students and helped us implementing reinforcement learning algorithms for language model that were conceived by Prof. Robert West whose lab I did my first postdoc in. 

Antonio took the FLUX model apart via principled ablation and activation patching experiments, where he would turn off certain components during the image generation process or replace them with values from a second forward pass generating a different image. The results he produced during this time, I think deserve to be displayed in a museum and are abstract pieces of art. But, beyond their aesthetic value they also revealed a lot about how FLUX generates images from text, which layers are important and how the textual processing stream interacts with the visual one. Importantly, Antonio maintained excellent notes on all of his findings, which not only helped him to organize his own thoughts but also to communicate his findings effectively to us. Antonio worked on his semester project very consistently, allocating enough time to it to make good progress. Semester project students are meant to spend about half of their time on their semester project, with which it is difficult for most, less consistent students to make good progress. Antonio's output was comparable to a master student working full time on their thesis, all while he only spend half of his time and took courses in addition to the project.

When Antonio learned about our ICML reviews this year (March 2025) and that the reviewers were asking for results on FLUX and whether our methods generalize to this more recent and architecturally different model, he took charge and independently revisited his activation steering experiments. Activation steering is closely related to the SAE steering we perform to turn on visual features within a spatial area, just instead adding multiples of a learned SAE direction to the intermediate states, this direction is computed by taking the difference of means of such intermediate states collected on a two datasets differing in a target concepts. E.g., to compute an age direction he would collect intermediate states of prompts resulting in images of young people and ones resulting in images of old people. He intelligently chose this setting to be able to debug the problems that we had when we tried steering with SAE directions in diffusion transformers with a rapid iteration speed -- avoiding the need of expensive SAE training for each experiment. To make activation steering work on FLUX was Antonio's greatest achievement in this project. His first experiments behaved very counter-intuitively and Viacheslav and I had already failed at our attempt. None of us knew whether steering would actually be possible for diffusion transformers like FLUX. However, one day after having tried everything imaginable Antonio had his breakthrough. He came up with the idea of decoupling feature extraction (taking the difference of means at a layer) and feature injection (adding that difference at the same layer when wanting to get the effect on a new image). Instead, he found that if he applied vectors extracted at layer 18 of the visual stream -- a key layer that he already identified during his exploratory phase to be causally influential to contents of the generated images -- to a range of layers, e.g., from layer 18 to the end, his steering interventions would work fabulously. He suddenly was able to change generated people from young to old and vice versa, from normal to pirate, from dry to wet, all the things that we only dreamed about when trying our SAEs the first time on FLUX.

Antonio's breakthroughs on FLUX are the reason why our paper "..." got accepted at NeurIPS 2025. He trained a SAE on layer 18 of FLUX, steered on multiple subsequent layers using the insights he gained via his steering setting and helped me incorperate his results into our paper. During the reviewing process, the fact that we had experimental results on FLUX made all the difference and got recognized by the reviewers. Beyond that, Antonio continued his work after the NeurIPS deadline, significantly improved our code base that stemmed from SDXL, a much smaller model with much smaller intermedate vectors, to a level of parallelism that it could handle FLUX SAE training without putting FLUX intermedate states to disk, which we simply could not afford in terms of memory requirements. In contrast, for SDXL we did not face this challenge. Using his new library that he coded up single handedly, he was able to train SAEs on every 6th layer of FLUX (an arbitrary choice, but FLUX is a 12 billion parameter model and has 58 layers in total). His scientific mindset and ambition drove him to perform a much more principled ablation study investigating different design choices for his FLUX SAEs and interventions than the one we had in the NeurIPS paper. He submitted another paper to ICLR 2026 summarizing his key findings. He did most of this including the experimentation and the writing process almost single handedly. Especially on the writing he is far more mature than most of his peers that could not achieve a comparable level of writing quality with that little guidance. 

Without Antonio's contributions our worksteam on the interpretability of text-to-image models would not be close to where it is today. Also, of course in order to achieve this he had to go much beyond the constraints of a regular semester project. I am closely collaborating with Antonio for about one year now.

The last proof of Antonio's remarkable leadership and maturity as a scientist that I am going to mention in this letter is that he started working as a mentor for Algoverse, a remote 12 week research program, in July 2025. In the scope of Algoverse, he mentored several groups of students on topics directly related to some of his findings on FLUX but also on other directions that he was curious about such as subliminal learning. He helped his mentees write up their findings and one of their papers got accepted at a NeurIPS 2025 workshop and two more of them at AAAI 2025 workshops.

To sum up, Antonio is carved from the same wood as the most capable young researchers I have encountered at ETH during my PhD, EPFL during my first postdoc and Northeastern, something that clearly shows in the quality of his project work. If it was up to me to decide I would hire Antonio for my own research group.

Sincerely,

Chris Wendler



February 2025 - June 2025
Joined DLAB to work on semester project “Diffusion models interpretability”.
I never worked on Diffusion models before, so this experience has been pivotal for everything that came next on this topic.

July 2025 - Present
Joined DLAB again for the optional semester project, to extend the previous work. Robert West supervises thesis I am writing at ETH Zürich, in Andreas Krause’s research group.

Core contributions:
Diffusion transformers (Flux) ablations: getting intuitive understanding of the role of all components of Flux, a model which had no technical documentation. Involved patching and disabling layers, and investigating the evolution and role of image and textual representation over 57 transformer blocks.
Steering vectors: showed that difference of activations can be used to find features on the latents of diffusion transformers which are semantic and causal and independent of the image location.
Found and explored high-norm activations in Flux, resembling ones reported in Vision Transformers but with unusual patterns.
Trained Sparse Autoencoder on Diffusion transformers (Flux), and developed a “repeated steering” procedure to detect layers to use for injecting concepts in model generation, as standard single-layer steering did not work.
Created RIEBench, a benchmark for interpretable image-editing, in order to evaluate quantitatively SAE features and interventions effect.
Used multi-steer to interpret models, finding which layers are responsible for what property of the image, including “adding objects”, “changing colors", “editing material”, “editing background”, ‘editing image style”.
Created “Residual API”, a criterion to determine which layers write and read a causal feature, extending to an activation-informed strategy, improving on RIEBench.

Achievements:
Semester project work got the previous paper that had been previously rejected to be extended with experiments, now including RIEBench benchmark and my SAEs on Flux → my contributions were core to get the paper accepted at NeurIPS 2025
The extension of the project (optional semester project) included work done during summer has been submitted to ICLR 2026
Work on flux was seminal for a group project on Diffusion-transformer based image-editing at course Visual Intelligence: Machines and Minds (CS-503, by Amir Zamir) and our project won the Best project Award, with a compensation of 100CHF per students to participate virtually in some conference of our choice
Work on High-norm activations and Steering vectors was useful for me to supervise student projects during summer, providing interesting line of researchs that were put in the backlog during the semester project work. This led to a submission to AAAI 2026 workshop.

